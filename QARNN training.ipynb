{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, FloatTensor\n",
    "from tools.DARNN import QARNN\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import concatenate as np_cat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm import trange\n",
    "from tools.DarnnTrainingTools import Trainer\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('data/all_data.parquet', engine='pyarrow')\n",
    "temp = pd.read_csv('data/weather_actual.csv')\n",
    "data = pd.concat([data, temp.iloc[:, 1:]], axis=1)\n",
    "del temp\n",
    "\n",
    "data = data.drop(columns=['time']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data: np.ndarray, T=72, P=48):\n",
    "        super().__init__()\n",
    "\n",
    "        self.x1 = []; x1_append = self.x1.append\n",
    "        self.x2 = []; x2_append = self.x2.append\n",
    "        self.y = []; y_append = self.y.append\n",
    "        self.length = data.shape[0] - T - P + 1\n",
    "\n",
    "        for i in trange(self.length):\n",
    "            x1 = data[i:i+T, -13:]  # actual weather\n",
    "            x1 = np_cat([x1, data[i+T:i+T+P, 1:14]], axis=0)  # actual & forecasted weather\n",
    "            x1 = np_cat([x1, data[i:i+T+P, 14:19]], axis=1)  # forecasted gens\n",
    "            x1_append(FloatTensor(x1))\n",
    "            \n",
    "            x2_append(FloatTensor(data[i:i+T, 0].reshape(T, 1)))\n",
    "            y_append(FloatTensor(data[i+T:i+T+P, 0]))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x1[index], self.x2[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDataset(data[:24*400])\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "\n",
    "val_set = CustomDataset(data[24*400:24*450])\n",
    "val_loader = DataLoader(train_set, batch_size=512, shuffle=False)\n",
    "\n",
    "test_set = CustomDataset(data[24*450:24*484])\n",
    "test_loader = DataLoader(test_set, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "model = QARNN(72, 48, 18, 32, 32).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "trainer = Trainer(criterion, device, 'checkpoints/qarnn_best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = trainer.train(model, optimizer, train_loader, val_loader, patience=10, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
